---
title: "GWAS with EM"
date: "`r paste0('Last update: ', format(Sys.time(), '%b %d, %Y'))`"    
---

$$
\newcommand{\E}{\text{E}}
$$

```{r setup}
rm(list = ls())
library(ggplot2)
library(dplyr)
theme_set(theme_bw(base_size=15))
set.seed(2020)

# load some gists
source('https://gist.githubusercontent.com/liangyy/43912b3ecab5d10c89f9d4b2669871c9/raw/3ca651cfa53ffccb8422f432561138a46e93710f/my_ggplot_theme.R')
source('https://gist.githubusercontent.com/liangyy/e580a36154586148cca7fd4cd973f502/raw/bad4364b1700662c7086fcdea191e42f530d0e2e/zval2pval.R')
```

# About

Here I test the idea that incoperating haplotype information in GWAS run with EM algorithm.
Essentially, it solves MLE of $\Pr(y | X)$ via intergrating $\Pr(y, Z | X)$ over $Z$.
I adapt the same simulation setup as [haplo_gwas_power](haplo_gwas_power.html).

# Simulation 

## Simulation for imputation

1. Simulate haplotypes for the parents, $H_i^{f, 1}, H_i^{f, 2}$ and $H_i^{m, 1}, H_i^{m, 2}$.
2. Simulate haplotypes for the child, $H_i^1, H_i^2$.
3. Simulate phenotypes for the parents, $y_{i, p}^f$ and $y_{i, p}^m$.
4. Simulate extra cohort for building PRS, $y_{i, p}$ and $X_{i, p}$

Some parameter settings:

```{r param1}
step1_sample_size = 10000
step1_sample_size_extra = 20000
step1_n_pheno = 20
step1_prior_causal = 0.1
step1_causal_sigma = 1
step1_n_snp = 1000
step1_heritabiltiy = 0.05
step1_maf_low = 0.05
step1_maf_high = 0.45
```

* Sample size $`r step1_sample_size`$.
* Sample size for PRS $`r step1_sample_size_extra`$.
* Number of phenotypes $`r step1_n_pheno`$.
* Effect size $\beta_{p, k} \sim \pi \delta_0 + (1 - \pi) N(0, \sigma)$ where $\pi = `r 1 - step1_prior_causal`$ and $\sigma^2 = `r step1_causal_sigma`$.
* Allele frequency $maf \sim Unif(`r step1_maf_low`, `r step1_maf_high`)$.
* Number of SNPs $`r step1_n_snp`$.
* Heritabillty $h^2 = `r step1_heritabiltiy`$ for all phenotypes.

## Simulation for association test

1. Simulate haplotypes for the father, $H^{f, 1}, H^{f, 2}$ and $H^{m, 1}, H^{m, 2}$.
2. Simulate phenotypes for the parents, $y^f$ and $y^m$.
3. Let $H^1 = H^{f, 1}$ and $H^2 = H^{m, 1}$.

Some paramter settings:

```{r param2}
step2_sample_size = 10000
step2_nrepeat = 500
step2_maf_low = 0.05
step2_maf_high = 0.45
step2_heritability = 0.001
step2_beta = 1
```

* Sample size $`r step2_sample_size`$.
* Number of replication $`r step2_nrepeat`$.
* Monor allele frequency $f \sim Unif(`r step2_maf_low`, `r step2_maf_high`)$.
* Heritability (note that it is single SNP scenario) $`r step2_heritability`$.

## Run simulation

Data for imputation.

```{r util}
source('../code/rlib_simulation.R')
```

```{r simulation1}
step1_maf = get_maf(step1_n_snp, step1_maf_low, step1_maf_high)
step1_h_father = sim_hap(step1_sample_size, step1_n_snp, step1_maf)
step1_h_mother = sim_hap(step1_sample_size, step1_n_snp, step1_maf)
step1_h_gwas = sim_hap(step1_sample_size_extra, step1_n_snp, step1_maf)
step1_h_child = transmit_haplo(step1_h_father, step1_h_mother)
step1_effect_size = matrix(spike_and_slab(step1_n_snp * step1_n_pheno, 1 - step1_prior_causal, step1_causal_sigma), nrow = step1_n_snp, ncol = step1_n_pheno)
step1_y_father = simulate_pheno(step1_h_father, step1_effect_size, step1_heritabiltiy, step1_maf)
step1_y_mother = simulate_pheno(step1_h_mother, step1_effect_size, step1_heritabiltiy, step1_maf)
step1_y_gwas = simulate_pheno(step1_h_gwas, step1_effect_size, step1_heritabiltiy, step1_maf)
```

Data for association test.

```{r simulation2}
step2_maf = get_maf(step2_nrepeat, step2_maf_low, step2_maf_high)
step2_h_father = sim_hap(step2_sample_size, step2_nrepeat, step2_maf)
step2_h_mother = sim_hap(step2_sample_size, step2_nrepeat, step2_maf)
step2_y_father = simulate_pheno_single_snp(step2_h_father, rep(step2_beta, step2_nrepeat), step2_heritability, step2_maf)
step2_y_mother = simulate_pheno_single_snp(step2_h_mother, rep(step2_beta, step2_nrepeat), step2_heritability, step2_maf)
step2_y_father_null = simulate_pheno_single_snp(step2_h_father, rep(0, step2_nrepeat), step2_heritability, step2_maf, null = TRUE)
step2_y_mother_null = simulate_pheno_single_snp(step2_h_mother, rep(0, step2_nrepeat), step2_heritability, step2_maf, null = TRUE)
```

# Haplotype imputation

## Estimated PRS

```{r estimated-prs-build}
# build PRS
source('../code/rlib_gwas.R')
build_prs = function(geno, pheno, prs_p_cutoff = 0.01) {
  n_snp = ncol(geno)
  n_pheno = ncol(pheno)
  effect_size_prs = matrix(0, nrow = n_snp, ncol = n_pheno)
  prs_p_cutoff = 0.01
  prs_z_cutoff = abs(qnorm(prs_p_cutoff / 2))
  for(pp in 1 : n_pheno) {
    message('Building phenotype ', pp)
    gwas = run_gwas(geno, pheno[, pp])
    pass_ind = abs(gwas$bhat / gwas$bhat_se) > prs_z_cutoff
    effect_size_prs[, pp][pass_ind] = gwas$bhat[pass_ind]
  }
  return(effect_size_prs)
}
step1_Xgwas = step1_h_gwas[[1]] + step1_h_gwas[[2]]
step1_effect_size_prs = build_prs(step1_Xgwas, step1_y_gwas)
```

## Run EM

```{r estimated-prs}
source('../code/rlib_em.R')
step1_g1 = step1_h_child[[1]] %*% step1_effect_size_prs
step1_g2 = step1_h_child[[2]] %*% step1_effect_size_prs
collector = list()
for(p in c(2, 5, 10, 20)) {
  o = em_algorithm(step1_y_father[, 1:p], step1_y_mother[, 1:p], step1_g1[, 1:p], step1_g2[, 1:p])
  collector[[length(collector) + 1]] = data.frame(z = o$z_prob_n, num_pheno = p, idx = 1 : length(o$z_prob_n))
}
df_estimated = do.call(rbind, collector)
```

# Run association test


Four schemes:

* imputed haplotype 
* haplotype with EM
* One step EM (LRT)
* Weighted Least squares

```{r gwas-prepare}
source('../code/rlib_gwas.R')
source('../code/rlib_em_otf_deg.R')

dm0 = list(
  X = rbind(
    (step2_h_father[[1]] + step2_h_mother[[1]]) / 2, 
    (step2_h_father[[1]] + step2_h_mother[[1]]) / 2
  ),
  y = rbind(
    step2_y_father, 
    step2_y_mother
  ), 
  ynull = rbind(
    step2_y_father_null,
    step2_y_mother_null
  )
)
dm1 = function(z) {
  list(
    X = rbind(
      step2_h_father[[1]] * z + step2_h_mother[[1]] * (1 - z),
      step2_h_father[[1]] * (1 - z) + step2_h_mother[[1]] * z
    ),
    y = rbind(
      step2_y_father, 
      step2_y_mother
    ), 
    ynull = rbind(
      step2_y_father_null,
      step2_y_mother_null
    )
  )
}
dm2 = list(
  X = rbind(
    step2_h_father[[1]],
    step2_h_mother[[1]]
  ),
  y = rbind(
    step2_y_father,
    step2_y_mother
  ),
  ynull = rbind(
    step2_y_father_null,
    step2_y_mother_null
  )
)

dm_old = function(z) {
  list(
    X = rbind(
      step2_h_father[[1]],
      step2_h_mother[[1]],
      step2_h_mother[[1]],
      step2_h_father[[1]]
    ),
    y = rbind(
      step2_y_father,
      step2_y_mother,
      step2_y_father,
      step2_y_mother
    ),
    ynull = rbind(
      step2_y_father_null,
      step2_y_mother_null,
      step2_y_father_null,
      step2_y_mother_null
    ),
    w = rbind(
      z,
      z, 
      (1 - z),
      (1 - z)
    )
  )
}

```


Actual GWAS run with imputed haplotype.

```{r gwas}
re = list()
ys = c('y', 'ynull')
types = c('beta = 1', 'beta = 0')

# Pr(Z) = 0.5
for(i in 1 : length(ys)) {
  o = run_gwas_pairwise(dm0$X, dm0[[ys[i]]])
  re[[length(re) + 1]] = data.frame(b = o$bhat, b_se = o$bhat_se, npheno = 0, type = types[i])
}

# Pr(Z) = gamma
for(npheno in unique(df_estimated$num_pheno)) {
  message('Working on npheno = ', npheno)
  zvec = df_estimated$z[df_estimated$num_pheno == npheno]
  zmat = matrix(rep(zvec, step2_nrepeat), nrow = step2_sample_size, ncol = step2_nrepeat)
  dm1_ = dm1(zmat)
  for(i in 1 : length(ys)) {
    o = run_gwas_pairwise(dm1_$X, dm1_[[ys[i]]])
    re[[length(re) + 1]] = data.frame(b = o$bhat, b_se = o$bhat_se, npheno = npheno, type = types[i])
  }
}

# Pr(Z) = 1
for(i in 1 : length(ys)) {
  o = run_gwas_pairwise(dm2$X, dm2[[ys[i]]])
  re[[length(re) + 1]] = data.frame(b = o$bhat, b_se = o$bhat_se, npheno = Inf, type = types[i])
}

df_re = do.call(rbind, re) %>% mutate(stat = b / b_se)
```

Actual GWAS run with EM and one-step EM with LRT

```{r gwas_em}
re = list()
re_onestep = list()

ylist_f = list(
  y = step2_y_father,
  ynull = step2_y_father_null
)

ylist_m = list(
  y = step2_y_mother,
  ynull = step2_y_mother_null
)


# Pr(Z) = 0.5
for(i in 1 : length(ys)) {
  o = run_gwas_pairwise_em(step2_h_father[[1]], step2_h_mother[[1]], ylist_f[[ys[i]]], ylist_m[[ys[i]]], weights = matrix(0.5, nrow = step2_sample_size, ncol = step2_nrepeat))
  re[[length(re) + 1]] = data.frame(b = o$bhat, b_se = o$bhat_se, npheno = 0, type = types[i])
  o = run_gwas_pairwise_em(step2_h_father[[1]], step2_h_mother[[1]], ylist_f[[ys[i]]], ylist_m[[ys[i]]], weights = matrix(0.5, nrow = step2_sample_size, ncol = step2_nrepeat), niter = 1)
  re_onestep[[length(re_onestep) + 1]] = data.frame(b = o$bhat, b_se = o$bhat_se, npheno = 0, type = types[i])
}

# Pr(Z) = gamma
for(npheno in unique(df_estimated$num_pheno)) {
  message('Working on npheno = ', npheno)
  zvec = df_estimated$z[df_estimated$num_pheno == npheno]
  zmat = matrix(rep(zvec, step2_nrepeat), nrow = step2_sample_size, ncol = step2_nrepeat)
  for(i in 1 : length(ys)) {
    o = run_gwas_pairwise_em(step2_h_father[[1]], step2_h_mother[[1]], ylist_f[[ys[i]]], ylist_m[[ys[i]]], weights = zmat)
    re[[length(re) + 1]] = data.frame(b = o$bhat, b_se = o$bhat_se, npheno = npheno, type = types[i])
    o = run_gwas_pairwise_em(step2_h_father[[1]], step2_h_mother[[1]], ylist_f[[ys[i]]], ylist_m[[ys[i]]], weights = zmat, niter = 1)
    re_onestep[[length(re_onestep) + 1]] = data.frame(b = o$bhat, b_se = o$bhat_se, npheno = npheno, type = types[i])
  }
}

# Pr(Z) = 1
for(i in 1 : length(ys)) {
  o = run_gwas_pairwise_em(step2_h_father[[1]], step2_h_mother[[1]], ylist_f[[ys[i]]], ylist_m[[ys[i]]], weights = matrix(1, nrow = step2_sample_size, ncol = step2_nrepeat))
  re[[length(re) + 1]] = data.frame(b = o$bhat, b_se = o$bhat_se, npheno = Inf, type = types[i])
  o = run_gwas_pairwise_em(step2_h_father[[1]], step2_h_mother[[1]], ylist_f[[ys[i]]], ylist_m[[ys[i]]], weights = matrix(1, nrow = step2_sample_size, ncol = step2_nrepeat), niter = 1)
  re_onestep[[length(re_onestep) + 1]] = data.frame(b = o$bhat, b_se = o$bhat_se, npheno = Inf, type = types[i])
}

df_re2 = do.call(rbind, re) %>% mutate(stat = b / b_se)
df_re4 = do.call(rbind, re_onestep) %>% mutate(stat = b / b_se)
```

The old scheme (Weighted Least squares).

```{r old_scheme}
re = list()

# Pr(Z) = 0.5
for(i in 1 : length(ys)) {
  zmat = matrix(0.5, nrow = step2_sample_size, ncol = step2_nrepeat)
  dm0_ = dm_old(zmat)
  o = run_gwas_pairwise(dm0_$X, dm0_[[ys[i]]], weights = dm0_$w)
  re[[length(re) + 1]] = data.frame(b = o$bhat, b_se = o$bhat_se, npheno = 0, type = types[i])
}

# Pr(Z) = gamma
for(npheno in unique(df_estimated$num_pheno)) {
  message('Working on npheno = ', npheno)
  zvec = df_estimated$z[df_estimated$num_pheno == npheno]
  zmat = matrix(rep(zvec, step2_nrepeat), nrow = step2_sample_size, ncol = step2_nrepeat)
  # setting 2
  dm1_ = dm_old(zmat)
  for(i in 1 : length(ys)) {
    o = run_gwas_pairwise(dm1_$X, dm1_[[ys[i]]], weights = dm1_$w)
    re[[length(re) + 1]] = data.frame(b = o$bhat, b_se = o$bhat_se, npheno = npheno, type = types[i])
  }
}


df_re3 = do.call(rbind, re) %>% mutate(stat = b / b_se)
```

# Analysis

```{r combine}
df = rbind(
  df_re %>% mutate(method = 'impute_haplotype'),
  df_re2 %>% mutate(method = 'haplotype_em'),
  df_re4 %>% mutate(method = 'haplotype_em_one_step'),
  df_re3 %>% mutate(method = 'weighted_least_squares')
) %>% mutate(snpid = rep(1:500, nrow(.) / 500))
```

## Sanity check

method `impute_haplotype`, `haplotype_em`, and `haplotype_em_one_step` should yield the same results at `npheno = Inf`.

```{r check1}
df_check = inner_join(
  df %>% filter(method == 'impute_haplotype', npheno == Inf),
  df %>% filter(method == 'haplotype_em', npheno == Inf),
  by = c('snpid', 'type'),
  suffix = c('.impute', '.em')
)
df_check %>% ggplot() + geom_point(aes(x = b.impute, y = b.em, color = type))
df_check %>% ggplot() + geom_point(aes(x = stat.impute, y = stat.em, color = type))
```

```{r check11}
df_check = inner_join(
  df %>% filter(method == 'impute_haplotype', npheno == Inf),
  df %>% filter(method == 'haplotype_em_one_step', npheno == Inf),
  by = c('snpid', 'type'),
  suffix = c('.impute', '.em')
)
df_check %>% ggplot() + geom_point(aes(x = b.impute, y = b.em, color = type))
df_check %>% ggplot() + geom_point(aes(x = stat.impute, y = stat.em, color = type))
```

Side by side comparison of EM vs one-step EM. They should not be exactly the same. 

```{r check12}
df_check = inner_join(
  df %>% filter(method == 'haplotype_em', npheno != Inf),
  df %>% filter(method == 'haplotype_em_one_step', npheno != Inf),
  by = c('snpid', 'type', 'npheno'),
  suffix = c('.em', '.em_one_step')
)
df_check %>% ggplot() + geom_point(aes(x = b.em, y = b.em_one_step, color = type))
df_check %>% ggplot() + geom_point(aes(x = stat.em, y = stat.em_one_step, color = type))
```

Side by side comparison of EM vs imputed haplotype. They should not be exactly the same. 

```{r check13}
df_check = inner_join(
  df %>% filter(method == 'haplotype_em', npheno != Inf),
  df %>% filter(method == 'impute_haplotype', npheno != Inf),
  by = c('snpid', 'type', 'npheno'),
  suffix = c('.em', '.impute')
)
df_check %>% ggplot() + geom_point(aes(x = b.em, y = b.impute, color = type))
df_check %>% ggplot() + geom_point(aes(x = stat.em, y = stat.impute, color = type))
```

Since they are checked as the same, we can treat them as equivalent results so that remove one of them.

```{r cc}
df_true = df %>% filter(method == 'impute_haplotype', npheno == Inf)
df_other = df %>% filter(npheno != Inf) %>% inner_join(df_true %>% select(b, b_se, stat, snpid, type), by = c('type', 'snpid'), suffix = c('', '.best'))
```

## Get $\gamma$-related stat

```{r gamma}
df_gamma = df_estimated %>% group_by(num_pheno) %>% summarize(mean_z = mean(z), mean_s = mean(z ^ 2 + (1 - z) ^ 2)) %>% ungroup()
df_gamma = rbind(
  df_gamma,
  data.frame(num_pheno = 0, mean_z = 0.5, mean_s = 0.5)
)
```

## Test stat under the null

```{r, fig.width=10, fig.height=8}
df_other %>% filter(type == 'beta = 0') %>% mutate(pval = zval2pval(stat)) %>% 
  group_by(method, npheno) %>% mutate(pexp = rank(pval) / n()) %>%
  ggplot() + geom_point(aes(x = -log(pexp), y = -log(pval), color = npheno)) +
  facet_wrap(~method) + 
  geom_abline(slope = 1, intercept = 0)
```

## Test stat under the alternative

```{r, fig.width=10, fig.height=8}
df_other %>% filter(type == 'beta = 1') %>% 
  ggplot() + geom_boxplot(aes(x = factor(npheno), y = stat / stat.best)) +
  facet_wrap(~method) + 
  geom_point(data = df_gamma, aes(x = factor(num_pheno), y = mean_z / sqrt(mean_s), color = 'theoretical'))
```


## Beta hat

```{r, fig.width=10, fig.height=4}
df_other %>% filter(type == 'beta = 1') %>% 
  ggplot() + geom_boxplot(aes(x = factor(npheno), y = b)) +
  facet_wrap(~method) + 
  geom_hline(aes(yintercept = 1, color = 'true')) + 
  geom_point(data = df_gamma, aes(x = factor(num_pheno), y = mean_z, color = 'theoretical_em')) +
  geom_point(data = df_gamma, aes(x = factor(num_pheno), y = mean_z / mean_s, color = 'theoretical_impute'))
```

# Conclusion

* Weighted least squares has inflated p-value.
* One-step EM based approach has deflated p-value (essentially it does LRT on weighted least squares).
* EM and imputed haplotype give quite similar statistics.
