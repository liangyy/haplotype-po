{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import argparse\r\n",
      "parser = argparse.ArgumentParser(prog='run_ukb_hap_bgen_to_hdf5.py', description='''\r\n",
      "    Convert BGEN into HDF5. \r\n",
      "    Work with ukb_hap_v2 BGEN.\r\n",
      "''')\r\n",
      "\r\n",
      "parser.add_argument('--bgen', help='''\r\n",
      "    BGEN file path\r\n",
      "''')\r\n",
      "parser.add_argument('--bgi', help='''\r\n",
      "    BGEN BGI file path\r\n",
      "''')\r\n",
      "parser.add_argument('--sample', help='''\r\n",
      "    BGEN SAMPLE file path\r\n",
      "''')\r\n",
      "parser.add_argument('--output-hdf5', help='''\r\n",
      "    HDF5 file name of output (if not exists, it will be created)\r\n",
      "''')\r\n",
      "parser.add_argument('--snp-chunk-size', type=int, default=100, help='''\r\n",
      "    Number of SNPs to process at a time\r\n",
      "''')\r\n",
      "parser.add_argument('--bgen-writing-cache-size', type=int, default=50, help='''\r\n",
      "    BGEN reading cache size in MB. (It should be set carefully: \r\n",
      "    pre-factor x nvariant x size of dtype x snp chunk size / 1024 ** 2\r\n",
      "    where pre-factor ~ 10)\r\n",
      "''')\r\n",
      "parser.add_argument('--max-sample-chunk-size', type=int, default=10000, help='''\r\n",
      "    Maximum size of chunk on sample axis.\r\n",
      "''')\r\n",
      "parser.add_argument('--max-snp-chunk-size', type=int, default=100, help='''\r\n",
      "    Maximum size of chunk on snp axis. \r\n",
      "''')\r\n",
      "parser.add_argument('--first-n-snp', type=int, default=None, help='''\r\n",
      "    If set, it will run on first N variants as test.\r\n",
      "''')\r\n",
      "args = parser.parse_args()\r\n",
      "\r\n",
      "import logging, time, sys\r\n",
      "# configing util\r\n",
      "logging.basicConfig(\r\n",
      "    level = logging.INFO, \r\n",
      "    stream = sys.stderr, \r\n",
      "    format = '%(asctime)s  %(message)s',\r\n",
      "    datefmt = '%Y-%m-%d %I:%M:%S %p'\r\n",
      ")\r\n",
      "\r\n",
      "from tqdm import tqdm\r\n",
      "import sys\r\n",
      "sys.path.insert(0, '../prs')\r\n",
      "import ukb_hap_reader\r\n",
      "import geno_hdf5\r\n",
      "\r\n",
      "\r\n",
      "def size_in_mb_to_cache_size(size):\r\n",
      "    return int(size * (1024 ** 2))    \r\n",
      "\r\n",
      "logging.info('Loading UKB HAP BGEN reader')\r\n",
      "reader = ukb_hap_reader.UKBhapReader(\r\n",
      "    bgen_path=args.bgen,\r\n",
      "    bgen_bgi_path=args.bgi,\r\n",
      "    sample_path=args.sample\r\n",
      ")\r\n",
      "\r\n",
      "logging.info('Building variant list')\r\n",
      "pos = [ int(i.split(':')[1]) for i in reader.variant_index.keys() ]\r\n",
      "non_effect_allele = [ i.split(':')[2] for i in reader.variant_index.keys() ]\r\n",
      "effect_allele = [ i.split(':')[3] for i in reader.variant_index.keys() ]\r\n",
      "chrom = [ '' for i in reader.variant_index.keys() ]\r\n",
      "\r\n",
      "logging.info('** Run on first {} variants'.format(args.first_n_snp))\r\n",
      "if args.first_n_snp is not None:\r\n",
      "    pos = pos[: args.first_n_snp]\r\n",
      "    non_effect_allele = non_effect_allele[: args.first_n_snp]\r\n",
      "    effect_allele = effect_allele[: args.first_n_snp]\r\n",
      "    chrom = chrom[: args.first_n_snp]\r\n",
      "\r\n",
      "logging.info('Loading sample list')\r\n",
      "with open(args.sample, 'r') as f:\r\n",
      "    sample_list = f.readlines()\r\n",
      "    sample_list.pop(0)\r\n",
      "    sample_list.pop(0)\r\n",
      "sample_list = [ i.split(' ')[0] for i in sample_list ]\r\n",
      "\r\n",
      "logging.info('Building variant generator')\r\n",
      "generator = reader.retrieve_from_list(\r\n",
      "    chrom=chrom,\r\n",
      "    pos=pos,\r\n",
      "    non_effect_allele=non_effect_allele,\r\n",
      "    effect_allele=effect_allele,\r\n",
      "    n_var_cached=args.snp_chunk_size\r\n",
      ")\r\n",
      "\r\n",
      "logging.info('Initializing genotype writer')\r\n",
      "geno_writer = geno_hdf5.GenotypeHDF5(\r\n",
      "    list_sample=sample_list,\r\n",
      "    num_variants=len(pos),\r\n",
      "    output_h5=args.output_hdf5,\r\n",
      "    dict_variant_meta={\r\n",
      "        'position': 'position',\r\n",
      "        'chromosome': 'chr',\r\n",
      "        'reference_allele': 'allele0',\r\n",
      "        'dosage_allele': 'allele1'\r\n",
      "    },\r\n",
      "    phased=True,\r\n",
      "    dtype=int,\r\n",
      "    cache_size=size_in_mb_to_cache_size(args.bgen_writing_cache_size)\r\n",
      ")\r\n",
      "\r\n",
      "logging.info('Converting')\r\n",
      "for dosage_row in tqdm(generator, total=len(chrom)):\r\n",
      "    geno_writer.fill_in(dosage_row, ['haplo_dosage_1', 'haplo_dosage_2'])\r\n",
      "\r\n",
      "logging.info('Saving') \r\n",
      "geno_writer.save()\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!cat ../run_ukb_hap_bgen_to_hdf5.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '../../prs/')\n",
    "import ukb_hap_reader\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from rpy2.robjects.packages import importr\n",
    "from rpy2.robjects import pandas2ri\n",
    "pandas2ri.activate()\n",
    "rbgen = importr('rbgen')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHR = 16\n",
    "BGEN = f'/vol/bmd/meliao/data/haplotype/hap/ukb_hap_chr{CHR}_v2.bgen'\n",
    "BGI = f'/vol/bmd/meliao/data/haplotype/hap_bgi/ukb_hap_chr{CHR}_v2.bgen.bgi'\n",
    "SAMPLE = '/vol/bmd/meliao/data/haplotype/link_files/ukb1952_v2_s487398.sample'\n",
    "reader = ukb_hap_reader.UKBhapReader(\n",
    "    bgen_path=BGEN,\n",
    "    bgen_bgi_path=BGI,\n",
    "    sample_path=SAMPLE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "nsnp_ = 27\n",
    "pos = [ int(i.split(':')[1]) for i in reader.variant_index.keys() ][:nsnp_]\n",
    "non_effect_allele = [ i.split(':')[2] for i in reader.variant_index.keys() ][:nsnp_]\n",
    "effect_allele = [ i.split(':')[3] for i in reader.variant_index.keys() ][:nsnp_]\n",
    "chrom = [ '' for i in reader.variant_index.keys() ][:nsnp_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query(pos):\n",
    "    query = pd.DataFrame({\n",
    "        'chromosome': [''],\n",
    "        'start': [int(pos)], # int(gwas_df.pos[i])],\n",
    "        'end': [int(pos)], # [int(gwas_df.pos[i])]\n",
    "    })\n",
    "    cached_data = rbgen.bgen_load(\n",
    "        BGEN,\n",
    "        index_filename=BGI,\n",
    "        ranges=query, \n",
    "        max_entries_per_sample=4\n",
    "    )\n",
    "    all_variants = pandas2ri.ri2py(cached_data[0])\n",
    "    if all_variants.shape[0] != 1:\n",
    "        raise ValueError('Extract no or more than 1 variant. Cannot handle.')\n",
    "    all_probs = pandas2ri.ri2py(cached_data[4])\n",
    "    return all_variants, all_probs\n",
    "def get_haplotype(probs):\n",
    "    return probs[:, 1], probs[:, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/vol/bmd/yanyul/miniconda3/envs/haplotype_po/lib/python3.7/site-packages/rpy2/robjects/pandas2ri.py:191: FutureWarning: from_items is deprecated. Please use DataFrame.from_dict(dict(items), ...) instead. DataFrame.from_dict(OrderedDict(items)) may be used to preserve the key order.\n",
      "  res = PandasDataFrame.from_items(items)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 0\n",
      "Processing 1\n",
      "Processing 2\n",
      "Processing 3\n",
      "Processing 4\n",
      "Processing 5\n",
      "Processing 6\n",
      "Processing 7\n",
      "Processing 8\n",
      "Processing 9\n",
      "Processing 10\n",
      "Processing 11\n",
      "Processing 12\n",
      "Processing 13\n",
      "Processing 14\n",
      "Processing 15\n",
      "Processing 16\n",
      "Processing 17\n",
      "Processing 18\n",
      "Processing 19\n",
      "Processing 20\n",
      "Processing 21\n",
      "Processing 22\n",
      "Processing 23\n",
      "Processing 24\n",
      "Processing 25\n",
      "Processing 26\n"
     ]
    }
   ],
   "source": [
    "_, p = query(pos[0])\n",
    "nsample = p.shape[1]\n",
    "out_mat = np.zeros((2, nsnp_, nsample), dtype=int)\n",
    "for i, pp in enumerate(pos):\n",
    "    print(f'Processing {i}')\n",
    "    _, probs = query(pp)\n",
    "    h1, h2 = get_haplotype(probs[0, :, :])\n",
    "    out_mat[0, i, :] = h1\n",
    "    out_mat[1, i, :] = h2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "with h5py.File('test_out.h5', 'r') as f:\n",
    "    genotype = f['genotype'][:]\n",
    "    pos_ = f['position'][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 27, 487409)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genotype.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 27, 487409)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_mat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([b'85629', b'85667', b'89659', b'92224', b'92370', b'92391',\n",
       "       b'92688', b'97610', b'101277', b'105325', b'106596', b'107211',\n",
       "       b'111247', b'112593', b'114123', b'114535', b'115072', b'118809',\n",
       "       b'119006', b'123220', b'125462', b'126588', b'128054', b'129025',\n",
       "       b'129223', b'131565', b'133946'], dtype=object)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[85629,\n",
       " 85667,\n",
       " 89659,\n",
       " 92224,\n",
       " 92370,\n",
       " 92391,\n",
       " 92688,\n",
       " 97610,\n",
       " 101277,\n",
       " 105325,\n",
       " 106596,\n",
       " 107211,\n",
       " 111247,\n",
       " 112593,\n",
       " 114123,\n",
       " 114535,\n",
       " 115072,\n",
       " 118809,\n",
       " 119006,\n",
       " 123220,\n",
       " 125462,\n",
       " 126588,\n",
       " 128054,\n",
       " 129025,\n",
       " 129223,\n",
       " 131565,\n",
       " 133946]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.testing.assert_array_equal(out_mat, genotype)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
