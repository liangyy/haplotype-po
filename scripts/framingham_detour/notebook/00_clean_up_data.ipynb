{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we need to organize the Framingham data in desired format and structure. \n",
    "\n",
    "* Expression data: convert the sample ID to subject ID so that it matches to the other data sets\n",
    "* Extract child-parent structure from the data.\n",
    "* Split the expression data into father matrix and mother matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "expression_file = '/lambda_stor/data/yanyul/Framingham/apt-gene/rma-sketch.summary.txt'\n",
    "pedigree_file = '/lambda_stor/data/yanyul/Framingham/40031/PhenoGenotypeFiles/RootStudyConsentSet_phs000007.Framingham.v23.p8.c1.HMB-IRB-MDS/PhenotypeFiles/phs000007.v23.pht000183.v10.p8.Framingham_Pedigree.MULTI.txt.gz'\n",
    "map_sample2subject = '/lambda_stor/data/yanyul/Framingham/43832/PhenoGenotypeFiles/ChildStudyConsentSet_phs000363.Framingham.v12.p9.c2.HMB-IRB-NPU-MDS/ExpressionFiles/phe000002.v5.FHS_SABRe_project3.sample-info.MULTI/phe000002.v5_release_manifest.txt'\n",
    "genotype_file = '/lambda_stor/data/yanyul/Framingham/imputed_hrc1.1/chr1.dose.vcf.gz'\n",
    "gene_annot_file = '/lambda_stor/data/yanyul/Framingham/haplotype_po_framingham/preprocess/microarray_gene_annotation.tsv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# outputs\n",
    "pedigree_out = '/lambda_stor/data/yanyul/Framingham/haplotype_po_framingham/preprocess/extracted_pedigree.tsv.gz'\n",
    "expression_full_out = '/lambda_stor/data/yanyul/Framingham/haplotype_po_framingham/preprocess/expression.all_indiv_w_genotype.tsv.gz'\n",
    "# expression_f_out = '/lambda_stor/data/yanyul/Framingham/haplotype_po_framingham/preprocess/expression.father.tsv.gz'\n",
    "# expression_m_out = '/lambda_stor/data/yanyul/Framingham/haplotype_po_framingham/preprocess/expression.mother.tsv.gz'\n",
    "active_individual_list_out = '/lambda_stor/data/yanyul/Framingham/haplotype_po_framingham/preprocess/all_indiv_w_genotype.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import gzip\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantile_norm(x):\n",
    "    temp = x.argsort()\n",
    "    ranks = np.empty_like(temp)\n",
    "    ranks[temp] = np.arange(len(x)) + 1\n",
    "    return stats.norm.ppf(ranks / (x.shape[0] + 1), loc=0, scale=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load expression matrix\n",
    "df_expr = pd.read_csv(expression_file, header=0, sep='\\t', comment='#')\n",
    "df_expr.probeset_id = df_expr.probeset_id.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load mapping between SampleID in expression matrix and subjectID used in elsewhere\n",
    "df_map = pd.read_csv(map_sample2subject, header=0, sep='\\t', comment='#', dtype={'SubjectID': str})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract the SampleID from expression matrix\n",
    "# along with the geneID column name for future use\n",
    "df_expr_columns = pd.DataFrame({'sampleID': df_expr.columns.tolist()[1:]})\n",
    "first_col_expr = df_expr.columns.tolist()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# annotate the SampleID with SubjectID and other meta information\n",
    "df_expr_columns = pd.merge(df_expr_columns, df_map, right_on='SampleID', left_on='sampleID', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only keep SampleID with consent == 1 (we're not allowed to use others)\n",
    "df_expr_columns_consent = df_expr_columns[ df_expr_columns.SubjectConsent == 1 ].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare the columns to extract from expression matrix \n",
    "# and how to rename the columns by SampleID\n",
    "desired_cols = [first_col_expr] + df_expr_columns_consent.SampleID.tolist()\n",
    "rename_dict = { df_expr_columns_consent.SampleID[i]: df_expr_columns_consent.SubjectID[i] for i in range(df_expr_columns_consent.shape[0]) }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract and rename expression matrix\n",
    "df_expr_extracted = df_expr[desired_cols].rename(columns=rename_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load individual list in genotype file\n",
    "with gzip.open(genotype_file, 'rt') as f:\n",
    "    for l in f:\n",
    "        if '##' in l:\n",
    "            continue\n",
    "        elif '#CHROM' in l:\n",
    "            e = l.strip().split('\\t')\n",
    "            e = e[9:]\n",
    "            break\n",
    "    indiv_list = e\n",
    "df_geno_indiv = pd.DataFrame({'SampleID': indiv_list})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep SampleID's that have genotype \n",
    "df_expr_extracted_indiv = df_expr_extracted.loc[:, df_expr_extracted.columns.isin(df_geno_indiv.SampleID) ].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# quantile normalize each gene\n",
    "for i in range(df_expr_extracted_indiv.shape[0]):\n",
    "    df_expr_extracted_indiv.loc[i, :] = quantile_norm(df_expr_extracted_indiv.loc[i, :])\n",
    "df_expr_extracted_probe = df_expr_extracted[['probeset_id']]\n",
    "df_expr_extracted = pd.concat((df_expr_extracted_probe, df_expr_extracted_indiv), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(expression_full_out):\n",
    "    # save the full expression matrix (for calculation of PEER factors)\n",
    "    df_expr_extracted.to_csv(expression_full_out, compression='gzip', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(active_individual_list_out):\n",
    "    # save the list of individuals apears in the full expression matrix (PCA will limit to these individuals)\n",
    "    with open(active_individual_list_out, 'w') as f:\n",
    "        for i in df_expr_extracted.columns[1:]:\n",
    "            f.write(i + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # load probe to gene id map\n",
    "# # and add gene id to probe\n",
    "# df_probe2gene = pd.read_csv(gene_annot_file, sep='\\t', dtype={'probeset_id': str})\n",
    "# df_expr_extracted = pd.merge(df_expr_extracted, df_probe2gene, \n",
    "#                                    left_on='probeset_id', right_on='probeset_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # shape of the extract expression matrix\n",
    "# df_expr_extracted.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load pedigree data\n",
    "df_pedigree = pd.read_csv(pedigree_file, compression='gzip', header=0, sep='\\t', comment='#', \n",
    "                          dtype={'fshare': str, 'mshare': str, 'shareid': str})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract individuals with both father and mother non-missing\n",
    "df_pedigree_complete = df_pedigree.loc[ \n",
    "    (df_pedigree.fshare.isna() == False) & \n",
    "    (df_pedigree.mshare.isna() == False) \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# furthermore, extract individuals with both parents observed in the expression matrix and themselves also\n",
    "df_pedigree_complete = df_pedigree_complete[ df_pedigree_complete.fshare.isin(df_expr_extracted.columns) & \n",
    "                                           df_pedigree_complete.mshare.isin(df_expr_extracted.columns) & \n",
    "                                           df_pedigree_complete.shareid.isin(df_expr_extracted.columns) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(550, 10)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# share of the leftover pedigree\n",
    "df_pedigree_complete.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEPRECATED\n",
    "# furthermore, we require all individuals in the extracted pedigree to occur in genotype file\n",
    "# df_pedigree_complete = df_pedigree_complete[ df_pedigree_complete.fshare.isin(df_geno_indiv.SampleID) & \n",
    "#                                            df_pedigree_complete.mshare.isin(df_geno_indiv.SampleID) &\n",
    "#                                            df_pedigree_complete.shareid.isin(df_geno_indiv.SampleID) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we further require that each mother and father occur only once\n",
    "df_pedigree_complete = df_pedigree_complete[\n",
    "    (~ df_pedigree_complete.fshare.duplicated()) & \n",
    "    (~ df_pedigree_complete.mshare.duplicated()) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(266, 10)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pedigree_complete.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ok, save the current extracted pedigree\n",
    "# future processing will be on the basis of it\n",
    "if not os.path.exists(pedigree_out):\n",
    "    df_pedigree_complete.to_csv(pedigree_out, index=False, sep='\\t', compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # next, we extract expression matrix of the fathers and the mothers\n",
    "# # indiv x gene (add another column to store the SampleID of the father/mother)\n",
    "# dict_expr_parents = {} \n",
    "# for parent in ['fshare', 'mshare']:\n",
    "#     dict_expr_parents[parent] = df_expr_extracted[ df_pedigree_complete[parent].tolist() ].T\n",
    "#     # rename the column with geneID\n",
    "#     # and add SampleID of the fathers as a column\n",
    "#     dict_expr_parents[parent].columns = df_expr_extracted[first_col_expr].tolist()\n",
    "#     dict_expr_parents[parent]['pSampleID'] = dict_expr_parents[parent].index\n",
    "#     dict_expr_parents[parent] = dict_expr_parents[parent].reset_index(drop=True)\n",
    "#     # add SampleID of the corresponding child\n",
    "#     dict_expr_parents[parent] = pd.merge(\n",
    "#         dict_expr_parents[parent], df_pedigree_complete[['shareid', parent]], \n",
    "#         left_on='pSampleID', right_on=parent, how='left'\n",
    "#     )\n",
    "#     # clean up the redundent columns\n",
    "#     dict_expr_parents[parent] = dict_expr_parents[parent].drop(columns=[parent]).rename(columns={'shareid': 'SampleID'})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
